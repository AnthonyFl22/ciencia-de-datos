#  PrÃ¡ctica II de Procesamiento del Lenguaje Natural

## ğŸ¯ Objetivo
Aplicar conceptos bÃ¡sicos de la **teorÃ­a de la informaciÃ³n** para evaluar la calidad de la informaciÃ³n de un texto, bajo un enfoque de **precisiÃ³n** y **sentido crÃ­tico**.

---

## ğŸ“‚ Parte 1: Preprocesamiento del texto

### ğŸ”¹ Archivos a utilizar
- `text_1.txt`  
- `text_2.txt`  
- `text_3.txt`  
- `text_4.txt`  
- `text_5.txt`  
- `libro_1.txt`  
- `libro_2.txt`  

### ğŸ”¹ Tareas
Crear una funciÃ³n que ejecute al menos lo siguiente (se pueden incluir mÃ¡s transformaciones opcionales):

- âœ… Convertir todo el texto a **minÃºsculas**.  
- âœ… Quitar **acentos** (ejemplo: `Ã¡ â†’ a`).  
- âœ… Eliminar los siguientes caracteres especiales:
  ; : , . \ - " ' / ( ) [ ] Â¿ ? Â¡ ! { } ~ < > | Â« Â» - â€” â€™ \t \n \r


---

## ğŸ“‚ Parte 2: Frecuencias a nivel de carÃ¡cter

1. Calcular la **frecuencia de apariciÃ³n de cada carÃ¡cter** en los archivos `text_1.txt` a `text_5.txt`.  
   - No se deben contar los **espacios en blanco**.  

2. Generar un **histograma** para cada archivo:  
   - Ordenar los caracteres de **mayor a menor frecuencia**.  

3. Interpretar cada histograma:  
   - Identificar quÃ© caracteres destacan.  
   - Explicar posibles razones de esta distribuciÃ³n.  

---

## ğŸ“‚ Parte 3: Frecuencias a nivel de palabra

1. Calcular las **frecuencias de palabras** en los archivos `libro_1.txt` y `libro_2.txt`.  

2. Responder para cada archivo:  
   - Â¿CuÃ¡ntas palabras hay en total?  
   - Â¿CuÃ¡ntas palabras Ãºnicas aparecen?  
   - Â¿CuÃ¡ntas palabras ocurren solo una vez (*hapax legomena*)?  

3. Generar **histogramas de palabras** ordenadas de mayor a menor frecuencia.  
   - Si hay demasiadas palabras, mostrar solo las mÃ¡s frecuentes (ejemplo: **las 30 mÃ¡s comunes**).  

---

## ğŸ“‚ Parte 4: EntropÃ­a

1. Calcular la **entropÃ­a a nivel de carÃ¡cter** en cada documento `text_1.txt` a `text_5.txt`.  
   - No considerar el **espacio en blanco**.  

2. Calcular la **entropÃ­a a nivel de palabra** en `libro_1.txt` y `libro_2.txt`:  
   - Primero con **todas las palabras**.  
   - Luego **eliminando las stopwords** (palabras como: `el`, `la`, `y`, `de`, etc.).  

---

## ğŸ“‚ Parte 5: N-gramas

1. Realizar una revisiÃ³n de **n-gramas** desde `n=2` hasta `n=5`.  
2. Responder:  
   -  Â¿QuÃ© patrones interesantes se encuentran en los textos?  

---

## ğŸ“¦ Entregables

El resultado de la prÃ¡ctica debe ser un **Notebook en Python** que contenga:

- CÃ³digo de **preprocesamiento**.  
- CÃ¡lculos de **frecuencias** y **entropÃ­a**.  
- **Histogramas** generados.  
- Respuestas e **interpretaciones** en celdas de texto.  

---

 **Nota:** Vamos modularizar el cÃ³digo en funciones reutilizables y mantener una estructura clara para facilitar la interpretaciÃ³n de los resultados.



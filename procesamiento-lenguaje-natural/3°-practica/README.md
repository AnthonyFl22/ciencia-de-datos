# üìò Pr√°ctica 3 ‚Äì An√°lisis de asociaciones con PMI

## üéØ Objetivo
El prop√≥sito de esta pr√°ctica fue analizar asociaciones significativas de palabras en t√≠tulos de noticias utilizando la medida de **Informaci√≥n Mutua Puntual (PMI, *Pointwise Mutual Information*)**.  

Con ello buscamos identificar pares de palabras que ocurren juntas m√°s frecuentemente de lo esperado por azar, lo cual permite detectar relaciones sem√°nticas en el lenguaje.

---

## üõ†Ô∏è Pasos realizados

### 1. Preprocesamiento de texto
- Conversi√≥n a **min√∫sculas**.  
- Eliminaci√≥n de **acentos**.  
- Eliminaci√≥n de caracteres especiales y puntuaci√≥n definidos:  

";:,.\-"'/()[]¬ø?¬°!{}~<>|¬´¬ª-‚Äî‚Äô\t\n\r"


- Normalizaci√≥n de espacios en blanco.  
- Tokenizaci√≥n en palabras.

> Para esta etapa se utiliz√≥ la funci√≥n `preprocess_text` desarrollada previamente en pr√°cticas anteriores.

---

### 2. Conjuntos de datos analizados
Se utilizaron tres archivos CSV con t√≠tulos de noticias, trabajando de manera independiente en cada uno:

- `archivo_emojis_Proceso.csv`
- `archivo_emojis_Elpais.csv`
- `archivo_emojis_Elfinanciero.csv`

De cada archivo se ley√≥ la columna **`title`**, que fue preprocesada y unida en un solo texto.

---

### 3. C√°lculo de asociaciones con PMI
1. A partir del texto preprocesado se generaron **bigramas** (pares de palabras consecutivas).  
2. Se calcularon las probabilidades:
 - Unigramas: `p(x)`  
 - Bigramas: `p(x, y)`  
3. Se aplic√≥ la f√≥rmula de PMI:  

 \[
 PMI(x,y) = \log_2 \frac{p(x,y)}{p(x)\,p(y)}
 \]

4. Se filtraron asociaciones que aparecen **al menos 10 veces** en el texto.  
5. Se seleccionaron las **10 asociaciones m√°s significativas** con mayor valor de PMI.

---

### 4. Resultados esperados
Para cada dataset (`Proceso`, `El Pa√≠s`, `El Financiero`) se obtuvo una tabla con las siguientes columnas:

- **w1** ‚Üí Primera palabra del bigrama.  
- **w2** ‚Üí Segunda palabra del bigrama.  
- **freq** ‚Üí Frecuencia absoluta de aparici√≥n del bigrama.  
- **pmi** ‚Üí Valor de informaci√≥n mutua puntual.  

La tabla presenta los **10 bigramas con mayor PMI**, es decir, las asociaciones de palabras m√°s relevantes.

---

## üìí Notebook
Todo el procedimiento se implement√≥ en un **notebook de Jupyter** que:
- Lee los datasets.  
- Preprocesa los textos.  
- Genera tokens y bigramas.  
- Calcula probabilidades y PMI.  
- Muestra las 10 asociaciones m√°s significativas por dataset.  

---

## ‚úÖ Conclusi√≥n
La pr√°ctica permiti√≥:
- Aplicar t√©cnicas de preprocesamiento de texto.  
- Construir modelos simples de lenguaje basados en n-gramas.  
- Identificar asociaciones relevantes en lenguaje natural mediante **PMI**.  

Esto constituye un paso hacia el an√°lisis sem√°ntico y la detecci√≥n de relaciones entre palabras en grandes vol√∫menes de texto.

El proyecto estÃ¡ modularizado en varios archivos `.py` para favorecer la reutilizaciÃ³n:

# ðŸ“– Proyecto de Procesamiento de Lenguaje Natural

El proyecto estÃ¡ modularizado en varios archivos `.py` para favorecer la **reutilizaciÃ³n** y la **claridad del cÃ³digo**.  
Cada mÃ³dulo se centra en una responsabilidad especÃ­fica.

---

## ðŸ“‚ scripts/

### **io_utils.py**
Funciones para manejo bÃ¡sico de archivos de texto:

- `read_text(path: str) -> str`  
  Lee el contenido completo de un archivo de texto (UTF-8). Ignora errores de decodificaciÃ³n.

- `write_text(path: str, content: str) -> None`  
  Escribe texto en un archivo (UTF-8). Si la ruta no existe, crea los directorios necesarios.

---

### **text_preprocess.py**
Funciones de limpieza y normalizaciÃ³n de texto:

- `strip_accents(s: str) -> str`  
  Elimina acentos y diacrÃ­ticos de una cadena (ej: `"canciÃ³n" â†’ "cancion"`).

- `preprocess_text(s: str) -> str`  
  Pipeline completo: minÃºsculas, quitar acentos, eliminar puntuaciÃ³n y normalizar espacios.

- `tokenize_words(s: str) -> List[str]`  
  Divide una cadena limpia en una lista de palabras.

- `characters_no_spaces(s: str) -> str`  
  Elimina **todos** los espacios y saltos de lÃ­nea de un texto.

---

### **freq_analysis.py**
Funciones para conteo de frecuencias:

- `char_frequencies(s: str) -> Counter`  
  Cuenta las frecuencias de caracteres.

- `word_frequencies(tokens: List[str]) -> Counter`  
  Cuenta las frecuencias de palabras.

- `top_items(counter: Counter, n: int) -> List[Tuple[str, int]]`  
  Devuelve los *n* elementos mÃ¡s comunes de un `Counter`.

---

### **entropy_utils.py**
Funciones para medir aleatoriedad:

- `shannon_entropy(items: Iterable) -> float`  
  Calcula la entropÃ­a de Shannon en bits sobre una secuencia de elementos.  
  Indica el nivel de incertidumbre: 0.0 es predictibilidad total, valores altos indican mayor aleatoriedad.

---

### **ngrams.py**
GeneraciÃ³n de secuencias de tokens:

- `ngrams(tokens: List[str], n: int) -> Counter`  
  Genera y cuenta *n*-gramas contiguos en una lista de tokens.  
  Ejemplo: con `n=2` y tokens `["el", "perro", "corre"]` genera `"el perro"`, `"perro corre"`.

---

### **plots.py**
VisualizaciÃ³n de frecuencias:

- `plot_histogram_from_counter(counter: Counter, title: str, max_items: int = None, rotation: int = 0)`  
  Genera un histograma de barras a partir de un `Counter`. Permite limitar el nÃºmero de Ã­tems y rotar etiquetas.

---

### **io_titles.py**
Funciones especÃ­ficas para datasets de noticias:

- `read_titles_csv(path: str | Path, title_col: str = "title") -> list[str]`  
  Lee un archivo CSV y devuelve la columna de tÃ­tulos como lista de strings.  
  Valida que la columna exista.

- `join_titles(titles: list[str]) -> str`  
  Une una lista de tÃ­tulos en un solo string separado por espacios.

---

### **pmi.py**
CÃ¡lculo de asociaciones de palabras usando **PMI** (*Pointwise Mutual Information*):

- `unigram_counts(tokens: list[str]) -> Counter[str]`  
  Cuenta frecuencias de unigramas.

- `bigram_counter_from_str_keys(counter_str: Counter[str]) -> Counter[tuple[str,str]]`  
  Convierte bigramas en string (`"w1 w2"`) a tuplas (`("w1","w2")`).

- `probabilities(tokens: list[str], bigram_c: Counter[tuple[str,str]])`  
  Calcula probabilidades unigramales y bigramales.

- `pmi_df(tokens: list[str], bigram_c: Counter[tuple[str,str]], min_freq: int = 1) -> pd.DataFrame`  
  Devuelve un DataFrame con pares de palabras, frecuencia y valor PMI.

---

### **report.py**
Funciones auxiliares para reportar resultados:

- `top_pmi(df: pd.DataFrame, k: int = 10) -> pd.DataFrame`  
  Selecciona las *k* asociaciones con mayor PMI.

- `save_table(df: pd.DataFrame, path: str) -> None`  
  Guarda un DataFrame en CSV.

